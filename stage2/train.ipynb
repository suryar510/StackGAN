{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import mean, exp, square, ones\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import *\n",
    "import stage2\n",
    "import stage1\n",
    "import os\n",
    "import pickle\n",
    "import PIL\n",
    "import time\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "\n",
    "def load(classes, embeddings, filenames):\n",
    "    with open(classes, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    with open(embeddings, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "    with open(filenames, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    return class_ids, embeddings, filenames\n",
    "\n",
    "\n",
    "def load_bounding_boxes(dataset_dir):\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
    "\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
    "                                    delim_whitespace=True, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Create a list of file names\n",
    "    file_names = df_file_names[1].tolist()\n",
    "\n",
    "    # Create a dictionary of file_names and bounding boxes\n",
    "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
    "\n",
    "    # Assign a bounding box to the corresponding image\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "        key = file_names[i][:-4]\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict\n",
    "\n",
    "\n",
    "def get_img(img_path, bbox, image_size):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(files, classes, embeds, cub, size):\n",
    "    class_ids, filed_embeddings, filenames = load(classes, embeds, files)\n",
    "    bounding_boxes = load_bounding_boxes(cub)\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    for index, filename in enumerate(filenames):\n",
    "        box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            name = cub + '/images/' + filename + '.jpg'\n",
    "            image = get_img(name, box, size)\n",
    "\n",
    "            all_embeddings = filed_embeddings[index, :, :]\n",
    "            embedding_ix = random.randint(0, all_embeddings.shape[0] - 1)\n",
    "            embedding = all_embeddings[embedding_ix, :]\n",
    "\n",
    "            X.append(np.array(image))\n",
    "            y.append(class_ids[index])\n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    X_data = np.asarray(X, dtype=np.float32)\n",
    "    y_data = np.asarray(y, dtype=np.float32)\n",
    "    embeddings = np.asarray(embeddings, dtype=np.float32)\n",
    "    return X_data, y_data, embeddings\n",
    "\n",
    "\n",
    "def buildModel(s1gen, s2gen, s2dis):\n",
    "    s1gen.trainable = False\n",
    "    s2dis.trainable = False\n",
    "\n",
    "    embed_inp = Input(shape=(1024,))\n",
    "    noise = Input(shape=(100,))\n",
    "    compressed_embed = Input(shape=(4, 4, 128))\n",
    "\n",
    "    s1_img, text1 = s1gen([embed_inp, noise])\n",
    "    s2_img, text2 = s2gen([embed_inp, s1_img])\n",
    "    out = s2dis([s2_img, compressed_embed])\n",
    "\n",
    "    mod = Model(inputs=[embed_inp, noise, compressed_embed], outputs=[out, text2])\n",
    "    return mod\n",
    "\n",
    "def klloss(true, pred):\n",
    "    mu = pred[:, :128]\n",
    "    ls = pred[:, :128]\n",
    "    loss = -ls + .5 * (-1 + exp(2. * ls) + square(mu))\n",
    "    loss = mean(loss)\n",
    "    return loss\n",
    "\n",
    "def save_rgb_img(image, path):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(image)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/suryar/Documents/ucb/mlab/stackgan/stage2/../birds\n",
      "Loading Training\n",
      "Loading Testing\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"/../birds\"# Training from within stage2 dir\n",
    "print(data_dir)\n",
    "train_dir = data_dir + \"/train\"\n",
    "test_dir = data_dir + \"/test\"\n",
    "batch_size = 64\n",
    "noise_dim = 100\n",
    "epochs = 1000\n",
    "cond_dim = 128\n",
    "\n",
    "embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\n",
    "filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "\n",
    "cub_dataset_dir = data_dir+\"/CUB_200_2011\"\n",
    "\n",
    "print(\"Loading Training\")\n",
    "X_train, y_train, embed_train = load_dataset(files=filenames_file_path_train,\n",
    "                                                 classes=class_info_file_path_train,\n",
    "                                                 embeds=embeddings_file_path_train,\n",
    "                                                 cub=cub_dataset_dir,\n",
    "                                                 size=(256, 256))\n",
    "print(\"Loading Testing\")\n",
    "X_test, y_test, embed_test = load_dataset(files=filenames_file_path_train,\n",
    "                                              classes=class_info_file_path_train,\n",
    "                                              embeds=embeddings_file_path_train,\n",
    "                                              cub=cub_dataset_dir,\n",
    "                                              size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stage2\n",
    "import importlib\n",
    "importlib.reload(stage2)\n",
    "import stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making gen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function _signal.default_int_handler>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_gen = stage2.generator()\n",
    "gen_opt = Adam(lr=.0002, beta_1=.5, beta_2=.99)\n",
    "s2_gen.compile(optimizer=gen_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "s1_gen = stage1.build_gen()\n",
    "s1_gen.compile(optimizer=gen_opt, loss=\"mse\")\n",
    "# s1_gen.load_weights(\"s1_gen.h5\")\n",
    "\n",
    "s2_dis = stage2.discriminator()\n",
    "dis_opt = Adam(lr=.0002, beta_1=.5, beta_2=.99)\n",
    "s2_dis.compile(optimizer=dis_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "compembed = stage1.build_compembed()\n",
    "compembed.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "model = buildModel(s1_gen, s2_gen, s2_dis)\n",
    "model.compile(optimizer=gen_opt, loss=['binary_crossentropy', klloss], loss_weights=[1.0, 2.0], metrics=None)\n",
    "\n",
    "real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "\n",
    "import sys\n",
    "import signal\n",
    "\n",
    "def signal_handler(signal, frame):\n",
    "    s2_dis.save_weights(\"s2_dis_interrupt.h5\")\n",
    "    s2_gen.save_weights(\"s2_gen_interrupt.h5\")\n",
    "    print(\"Saved interrupted weights, backup if you want them.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442c66b9ec354b65991e789954f60190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "EPOCH: 0\n",
      "\tBatch: 0\n",
      "\t\td_loss_real:[0.94329107, 0.0]\n",
      "\t\td_loss_fake:[11.5446825, 0.0]\n",
      "\t\td_loss_wrong:[10.541672, 0.0]\n",
      "\t\tdis_loss:[5.9932337 0.       ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8bfbe7d6d8ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\tdis_loss:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membed_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompembed_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\tmodel_loss:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdis_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           standalone=True)\n\u001b[0m\u001b[1;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m   1080\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tnrange(epochs):\n",
    "    print(\"=====================\\nEPOCH: {}\".format(epoch))\n",
    "    gen_opt.learning_rate.assign(gen_opt.learning_rate/2)\n",
    "\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "\n",
    "    num_batch = int(X_train.shape[0] / batch_size)\n",
    "    for index in range(num_batch):\n",
    "        print(\"\\tBatch: {}\".format(index))\n",
    "        noise_batch = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "        image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "        image_batch = (image_batch - 127.5) / 127.5\n",
    "        embed_batch = embed_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "        fake_image_1, _ = s1_gen.predict([embed_batch, noise_batch], verbose=3)\n",
    "        fake_image_2, _ = s2_gen.predict([embed_batch, fake_image_1], verbose=3)\n",
    "\n",
    "        compembed_batch = compembed.predict_on_batch(embed_batch)\n",
    "        compembed_batch = np.reshape(compembed_batch, (-1, 1, 1, cond_dim))\n",
    "        compembed_batch = np.tile(compembed_batch, (1, 4, 4, 1))\n",
    "\n",
    "        dis_loss_real = s2_dis.train_on_batch([image_batch, compembed_batch],\n",
    "                                           np.reshape(real_labels, (batch_size, 1)))\n",
    "        dis_loss_fake = s2_dis.train_on_batch([fake_image_2, compembed_batch],\n",
    "                                           np.reshape(fake_labels, (batch_size, 1)))\n",
    "        dis_loss_wrong = s2_dis.train_on_batch([image_batch[:(batch_size - 1)], compembed_batch[1:]],\n",
    "                                            np.reshape(fake_labels[1:], (batch_size - 1, 1)))\n",
    "        dis_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
    "        print(\"\\t\\td_loss_real:{}\".format(dis_loss_real))\n",
    "        print(\"\\t\\td_loss_fake:{}\".format(dis_loss_fake))\n",
    "        print(\"\\t\\td_loss_wrong:{}\".format(dis_loss_wrong))\n",
    "        print(\"\\t\\tdis_loss:{}\".format(dis_loss))\n",
    "\n",
    "        loss = model.train_on_batch([embed_batch, noise_batch, compembed_batch], [ones((batch_size, 1)) * 0.9, ones((batch_size, 256)) * 0.9])\n",
    "        print(\"\\t\\tmodel_loss:{}\".format(loss))\n",
    "        dis_losses.append(dis_loss)\n",
    "        gen_losses.append(loss)\n",
    "\n",
    "    print(\"Saving weights\")\n",
    "    s2_dis.save_weights(\"s2_dis_%d.h5\" % epoch)\n",
    "    s2_gen.save_weights(\"s2_gen_%d.h5\" % epoch)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        test_noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "        test_embed = embed_test[0:batch_size]\n",
    "        s1_img, _ = s1_gen.predict([test_embed, test_noise], verbose=3)\n",
    "        s2_img, _ = s2_gen.predict([test_embed, s1_img], verbose=3)\n",
    "\n",
    "        for idx, img in enumerate(s2_img[:5]):\n",
    "            save_rgb_img(img, \"logs/img{}_{}.png\".format(epoch, idx))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        gen_opt.learning_rate.assign(gen_opt.learning_rate/2)\n",
    "        dis_opt.learning_rate.assign(dis_opt.learning_rate/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
